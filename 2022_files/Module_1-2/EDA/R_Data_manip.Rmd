---
title: "R data manipulation"
author: "Sean Harrington"
date: "2/3/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '~/r4grads')

```


We will explore some basic data manipulation, including reading, filtering, and transforming. This will all be taking place in R. I **highly** recommend writing all of your code in an R script and commenting it liberally. Even for relatively simple operations, if you need to repeat them or slightly tweak them, it's much easier to simply open up your script and re-run it or edit it than to re-type everything into R. Even more importantly, it ensures that there is a record of exactly what you did. If you haven't already dealt with trying to remember how you handled data when you come back it to after a while, you'll probably be surprised by just how quickly you can forget what you were doing and why.


### Reading in the data

Start by setting out working directory.

```{r, eval = FALSE}
setwd("~/r4grads")
```

We will also create an object with the path to our data directory.
```{r}
data_dir <- "~/r4grads/Fish_data/Modified/"
```


Then read in the data. Here, we have the data in two separate csv files for different data pertaining to some fish. One file is body size data with some information about sampling and the species, and the other file contains stable isotope data. Note that we're using `paste0()` inside `read.csv()` to paste together the paths and file names.

```{r}
body <- read.csv(paste0(data_dir, "/", "Fish_body_size.csv"))
iso <- read.csv(paste0(data_dir, "/","Fish_isotopes.csv"))
```


Let's take a quick look at the top few rows of each dataset.


```{r}
head(body)
head(iso)
```

We can also look at the bottom few rows.
```{r}
tail(body)
```

See how many rows and columns are in each dataframe:

```{r}
dim(body)
dim(iso)
```


Let's take a look at what species are included and how many samples we have of each species.

```{r}
unique(body$Species)

summary(as.factor(body$Species))
```



### Fixing spelling
Looking at either of those last outputs, you should notice that we have some misspellings. In some cases, "Coho" was written in all capital letters, and because R is case sensitive (as are most other coding languages), these are interpreted as different species. We also have "Dolly Varden" abbreviated down to just "Dolly" in one case, and a misspelling of "Steelhead" as "Steelhesd". We will want to correct these before we move forward with any further data processing.

There are a few ways to do this. One is by using an indexing approach to identify all of the elements of the objects that contain the values we want to replace, and replacing them with the values we want.

Let's build this out:

We'll start by identifying which elements of the "Species" column of `body` contains `"COHO"`
```{r, eval=FALSE}
body$Species=="COHO"
```

You should see a long list of TRUE/FALSE values corresponding to whether each element is (TRUE) or is not (FALSE) "COHO". We can then use this to select out only the TRUE elements of `body$Species`:

```{r, eval=FALSE}
body$Species[body$Species=="COHO"]
```


And finally, using that indexing to identify the incorrect entries, we can replace them with "Coho":
```{r}
body$Species[body$Species=="COHO"] <- "Coho"
```


But there are also much faster ways to do this. The function `gsub()` will search for all occurrences of its first argument and replace them with its second argument in the object specified in the third argument:

```{r}
body$Species <- gsub("^Dolly$", "Dolly varden", body$Species)
body$Species <- gsub("Steelhesd", "Steelhead", body$Species)
```

In the above, the `^` indicates the start of a string and the `$` indicates the end of string of a string, indicating that only want to replace Dolly when the D is the start of a string and the y is the end -- why is this necessary? What happens if we just replace `Dolly`?

If we take a look at the data again, we should see that these errors have been corrected:

```{r}
unique(body$Species)
summary(as.factor(body$Species))
```


We should also know how many species we sampled, and we can check how many are in this dataset:

```{r}
length(unique(body$Species))
```

We also have a similar error in `body$Site` that we'll fix real quick:
```{r}
body$Site <- gsub("RT02-R", "RT02R", body$Site)
sort(unique(body$Site))
```

These look pretty good now. Note that misspellings like these are relatively easy to catch, but incorrect numerical values can be much harder. Those errors will typically require plotting of the data to identify obviously incorrect values, which we'll cover later on. 



### Merging the data

Before we continue on, we'd like to have all of our data in a single object. This is simpler to keep track of and also allows us to apply filters and manipulations to the entire dataset at once, rather than needing to modify each object individually.

When merging, datasets may not include the same exact samples or samples may be in different orders, so we can't just stick the columns all together. If we look at the dimensions of our two dataframes again, we'll notice that they have different numbers of rows, indicating that at least one sample is in one set but not the other.

We can check for `Fish.code` elements that are in the body size data but not the isotope data:

```{r}
which(!body$Fish.code %in% iso$Fish.code)
```

the `%in%` operator checks for occurrences of the preceding object in the following object, and returns a vector of TRUE/FALSE. The `!` at the beginning reverses TRUE/FALSE, so that TRUE instead corresponds to elements of `body$Fish.code` that are NOT in `iso$Fish.code`, and the `which()` gives us the numeric indices of the elements of the TRUE/FALSE vector that are true. The result is that the numbers this spits out are the indices of `body$Fish.code` that are NOT in `iso$Fish.code`.

We can use this as an index to get the actual values of `body$Fish.code` that are not shared by `iso$Fish.code`:

```{r}
body$Fish.code[which(!body$Fish.code %in% iso$Fish.code)]
```

and we can run the same check in reverse order to see values of `iso$Fish.code` not in `body$Fish.code`:

```{r}
iso$Fish.code[which(!iso$Fish.code %in% body$Fish.code)]
```


We can see that we have a total of 9 samples that are present in one of the datasets, but not the other. We can identify which fish are in both datasets:

```{r}
in_both <- intersect(iso$Fish.code, body$Fish.code)
```

```{r, eval=FALSE}
in_both
```

Then we can use that to subset both of the datasets down to only these sahred samples, both in the same row order:

```{r}
iso_red <- iso[iso$Fish.code %in% in_both, ]
body_red <- body[body$Fish.code %in% in_both, ]
dim(iso_red)
dim(body_red)
```


Both of these objects now have the same number of rows, and we know that they are in the same row order because we indexed them both from the same object in the same way. 

Note that when indexing a dataframe or other objects that have both rows and columns, we index using a `[row,column]` format. If we are selecting all columns, we can simply leave the portion after the comma blank, but we must still include the comma. The reverse is true for selecting all rows and certain columns.

We can now simply bind these columns together:

```{r}
all_data1 <- cbind(body_red, iso_red)
head(all_data1)
```



This leaves us with two "Fish.code" columns, however, so we can can use the numeric index of the second of these to drop out the column that we don't need:

```{r}
all_data2 <- all_data1[,-7]
head(all_data2)
dim(all_data2)
```

This looks better. This is a fairly long and tedious way of combining dataframes, though. We can actually achieve all of this with a single function:

```{r}
all_data <- merge(body, iso)
head(all_data)
dim(all_data)
```

This has the same dimensions as the way that did this above using indexing and `cbind`. Looks good. Before we continue on, let's write this to a csv file. Then we can easily read this cleaned and merged data into R or another program anytime we want without having to repeat these steps:

```{r}
write.csv(all_data, paste0(data_dir, "/", "fish_data_merged.csv"))
```


### Further filtering and subsetting examples

Let's read that csv file back into R, just to demonstrate it.

```{r}
all_data <- read.csv(paste0(data_dir, "/", "fish_data_merged.csv"))
```

For some analyses, we might want to analyze a single species of fish at a time. We can do this similarly to how we used row indexing to merge datasets above.


```{r}
coho_data <- all_data[all_data$Species == "Coho",]
head(coho_data, n=4)
```

We could simultaneously select out a single species and only the `Fish.code` and `Fork.length..cm.` columns.

```{r}
coho_length <- all_data[all_data$Species == "Coho", c("Fish.code", "Fork.length..cm.")]
head(coho_length, n=4)
```

We can select two or more species at once in a couple different ways:

```{r}
cs_data <- all_data[all_data$Species %in% c("Coho", "Steelhead"),]
```
```{r, eval=FALSE}
cs_data
```


Or using more complex pattern matching:

```{r}
cs_data1 <- all_data[all_data$Species == "Coho" | all_data$Species == "Steelhead",]
```
```{r, eval=FALSE}
cs_data1
```

where the pipe `|` indicates that we want to match the first condition or the second condition.

We can also use `&` to get only rows that satisfy two or more conditions. E.g., we can find the Coho that are smaller than 10 g:

```{r}
coho_small <- all_data[all_data$Species == "Coho" & all_data$Weight..g. < 10,]
```
```{r, eval=FALSE}
coho_small
```

### Transforming data

R makes it very easy to transform or otherwise convert data. Operations can be applied across entire vectors or columns of dataframes easily. We can easily log-transform our body size data:


```{r}
log_weight <- log(all_data$Weight..g.)
data_w_log <- cbind(all_data, log_weight)
```


### Handling NAs (not applicable/empty data)

R treats NA data differently than other types of data. For this reason, we need special tools if we want to remove NA. To demonstrate this, let's first introduce some NAs into our data. We'll convert all values of "Fork.length..cm." less than 5 to NA:

```{r}
all_data$Fork.length..cm.[all_data$Fork.length..cm. < 5] <- NA
```
```{r, eval=FALSE}
all_data$Fork.length..cm.
```

If we try to check if values are NA the same way that we've evaluated things so far, it won't work:

```{r, eval=FALSE}
all_data$Fork.length..cm.==NA
```

And in fact, if you're using RStudio and put the above line in a script, it will flag that line and mousing over the exclamation mark will tell you to use `is.na()`. Let's try that instead:

```{r, eval=FALSE}
is.na(all_data$Fork.length..cm.)
```

This looks like what we'd expect, and we can use this to filter out NAs in this row. Note that many functions can include NA values, so completely removing NA data may not always be desirable. It will depend heavily on your specific dataset.

```{r}
data_noNA <- all_data[!is.na(all_data$Fork.length..cm.),]
```

Notice the `!` in the above line that lets us keep everything that is *not* NA. Now if we check if we have any NAs in the `Fork.length..cm.` of this new object, we should not get any:

```{r}
which(is.na(data_noNA$Fork.length..cm.))
```

