---
title: "Tidyverse and data visualization"
author: "Sean Harrington"
date: "2023-03-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/r4grads/Fish_data/Modified/")
```

<br>

[Home](https://wyoibc.github.io/r4grads/)

<br>
<br>

## Set up:

If you don't have the data from last time handy, or have forgotten where you put it, use the instructions from the [week 2 session](https://wyoibc.github.io/r4grads/Module_2/R_Data_manip.html) to re-download it. Then set your working directory to where the data are:

```{r, eval = FALSE}
setwd("~/r4grads/Fish_data/Modified/")
```

We'll need our `all_data` object again. If you have your `"fish_data_merged.csv"` file that we wrote out last time, you can read in:

```{r}
all_data <- read.csv("fish_data_merged.csv")
```

If you've lost track of this file, we can create it again:

```{r}
# read in each of the data files
body <- read.csv("Fish_body_size.csv")
iso <- read.csv("Fish_isotopes.csv")
# Make all of the subsitutions that we made last time
body$Species <- gsub("Steelhesd", "Steelhead", body$Species)
body$Species <- gsub("COHO", "Coho", body$Species)
body$Species <- gsub("^Dolly$", "Dolly varden", body$Species)
body$Site <- gsub("RT02-R", "RT02R", body$Site)
body$Site <- gsub("RT02-BP", "RT02BP", body$Site)
# Merge the data
all_data <- merge(body, iso)
```

<br>
<br>

# Tidyverse

<br>

So far, we've done all of the manipulation using base R functions. We can also do a lot of fancy data manipulation using the [Tidyverse](https://www.tidyverse.org/) set of R packages, which all share some general principles in their architecture. I won't go into the details of the Tidyverse philosphy, as it's very well documented and you can read all about it at the link.


<br>

To start, you'll need to make sure you have the Tidyverse packages installed and then loaded:

```{r eval = FALSE}
install.packages("tidyverse")
```
```{r}
library(tidyverse)
```

<br>

Before we actually start doing anything, there's an important issue to point out in this loading message. The conflicts show that there are functions in `dplyr` and the base R `stats` packages that share the same function names. Whenever this happens, the function from the most recently loaded package will mask the other function. If you load `dplyr` last and then run `filter()`, what you'll get is the function from `dplyr`. Alternately, if you load `stats` last, you'll get the `filter()` function from that package.

This is important to keep track of. Especially if you write a script and then edit it to load up a package at the the top of a script. You can always call a function from a specific package by using the notation `package::function()`. The double colons tell R to explicitly use a function from the stated package before the colons.

<br>


Some of these functions are very similar to base R functions. E.g., `str_replace()` is very similar to `gsub()`, but with a different order of arguments: 

```{r}
body <- read.csv("Fish_body_size.csv")
body$Species <- str_replace(body$Species, "Steelhesd", "Steelhead")
```


<br>

## dplyr and tidyr for filtering and summarizing

<br>

We can filter data using the `filter()` function, this is similar to how we filtered data using base R:

```{r, results = FALSE}
coho_data <- filter(all_data, Species == "Coho")
coho_data
big_coho <- filter(all_data, Species == "Coho" & Fork.length..cm. > 10)
big_coho
```

We can select only certain columns using `select()`:

```{r, results = FALSE}
big_coho_size_vars <- select(big_coho, Weight..g., Fork.length..cm.)
big_coho_size_vars
```

We can add in columns that are combinations or transformations of others:

```{r, results = FALSE}
big_coho2 <- mutate(
  big_coho,
  mass2 = Weight..g. * 2,
  mass2_squared = mass2 ^ 2
)
big_coho2
```

<br>

We can also get useful summaries of our data grouped however we want. E.g., we can get the mean weight of each species from our `all_data` object:

```{r}
by_spec <- group_by(all_data, Species)
summarise(by_spec, size = mean(Weight..g., na.rm = TRUE))
```


<br>

Tidyverse has all sorts of functions like these that each do specific data manipulations that you can explore at your leisure. Many people love Tidyverse and use it for all of their data manipulation, others prefer to use base R for basic manipulations and use Tidyverse only for more complex operations. It's totally up to you which you prefer and which makes more sense to you.

<br>

## Tibbles

On top of all sorts of functions, Tidyverse also introduces a couple other important pieces of functionality: tibbles and pipes.

Tibbles are effectively an extension of the dataframe format that has very specific rules. You can read all about them [here](https://tibble.tidyverse.org/).

You can convert dataframes to tibbles like so:


```{r}
big_coho_tib <- as_tibble(big_coho)
big_coho_tib
```

Notice that this prints differently from a dataframe. There are some other key differences, including that Tibbles do not have row names (instead this information is expected to be as a column within the tibble). Use whichever you prefer. In many cases, they operate pretty much interchangeably, although some functions from various packages will require input data to be in one of the formats or the other -- it is easy to convert back and forth, though.


<br>

You can also read data into R straight into a tibble using Tidyverse functions:

```{r}
body_tib <- read_csv("Fish_body_size.csv")
body_tib
```




Note that is almost the same as the base `read.csv()` function, just with an underscore instead of a period. You can also read in tab delimited data using `read_tsv()` and there are probably Tidyverse equivalents of most functions to read in data.

<br>
<br>

## Pipes

<br>

Pipes allow you to chain (or "pipe") together multiple functions into a single long command. If you're familiar with the Linux/Unix command line, this is done with the `|` character. R uses that for some other purposes, so Tidyverse instead introduces the pipe as `%>%`.


When you pipe a function to another function, the output from the first function becomes the data argument of the second function, and you can link many pipes together.

<br>

For example, we can pipe together all of the commands we used above to make the big_coho2 object:


```{r}
big_coho3 <- filter(all_data, Species == "Coho" & Fork.length..cm. > 10) %>%
  select(Weight..g., Fork.length..cm.) %>%
  mutate(
    mass2 = Weight..g. * 2,
    mass2_squared = mass2 ^ 2
  )
big_coho3
```


<br>

Try out piping together `group_by()` and `summarise()` to get an object that has the mean and standard deviation of the weight of each species from the `all_data` object. You'll need to look up what functions calculate means and standard deviations.

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

```{r, results = FALSE}
weight_sum <- group_by(all_data, Species) %>%
  summarise(size = mean(Weight..g., na.rm = TRUE), stdev = sd(Weight..g., na.rm = TRUE))

weight_sum
```


<br>

We could also add in some other columns using mutate:

```{r}
weight_sum2 <- group_by(all_data, Species) %>%
  summarise(
    size = mean(Weight..g., na.rm = TRUE), 
    stdev = sd(Weight..g., na.rm = TRUE)
    ) %>%
  mutate(
    lower = size - stdev,
    upper = size + stdev
    )

weight_sum2
```

<br>

Here, I've split up single functions onto multiple lines to improve readability: each column being created by `summarise()` and `mutate()` gets its own line.



<br>

There are advantages and disadvantages to piping together commands. A major advantage is that you don't need to store intermediate data objects that you aren't going to use as objects in R's memory. A disadvantage is that if you pipe together too many commands, your code can start to become less readable.

<br>
<br>

As already mentioned, we've really only scarped the surface of how to manipulate data with either base R or Tidyverse. There is a whole book [R for Data Science](https://r4ds.had.co.nz/index.html) written by the primary developers (or at least originators) of Tidyverse. That link will take you to the site for the free book, which is filled with code examples.

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


# Exploratory data visualization

So far, we've explored how we can manipulate our data in R, including reading in, subsetting, and merging datasets. These are all very important, but looking at data in the ways we have so far doesn't give us a good intuition for what kind of patterns or distributions there are in the data. Do we have mostly large fish? Mostly small fish? Are the data roughly normally distributed? If you have far better mathematical intuition than I do, you might be able to guess at this from looking at a dataframe in the R console, but I sure can't. Plotting the data gives us a much better idea of what's going on.  

We'll start with a few basic plots using base R functionality, then move onto fancier graphics in ggplot.

<br>

### Relationships among continuous variables

When collecting data, we likely have some hypotheses that we are testing or at least general ideas about what kinds of patterns we expect in the data. In many cases, we may hypothesize that two variables are correlated. We can visualize the association between two variables using a scatterpot.

Let's quickly remind ourselves of the variables that are in our fish dataset:

```{r}
colnames(all_data)
```


We would probably expect a relationship between weight and fork length, since it makes sense that longer fish are probably heavier fish. Let's see what it looks like:

```{r}
plot(all_data$Fork.length..cm., all_data$Weight..g.)
```

<br>

Cool, looks like there's a relationship here, but it's pretty hideous, so let's clean it up a little.

```{r}
plot(all_data$Fork.length..cm., all_data$Weight..g.,
     pch = 16, frame = FALSE, col = "blue", cex=0.5,
     ylab="Weight (g)", xlab = "Fork length (cm)")
```

There are a number of other graphical parameters you can tweak as you like. There are good resources all over the internet that can be easily found by searching things like "base R axis labels".

<br>

This plot gives us a pretty good idea that there's a correlation between our data, but it looks distinctly non-linear. This isn't surprising, since larger fish don't just get longer, but also wider and taller, so we'd expect the mass to increase more than linearly. This is a good example of when we might want to transform our data. 

**Try cube root transforming weight and then plot that against fork length.** We're using the cube root because mass typically increases cubically as a function of length (assuming that other dimensions stay roughly proportional). Remember that a cube root is the same as raising a number to the power of 1/3.

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


```{r}
cube_weight <- all_data$Weight..g.^(1/3)
plot(all_data$Fork.length..cm., cube_weight,
     pch = 16, frame = FALSE, col = "blue", cex=0.5,
     ylab="Cube root weight (g)", xlab = "Fork length (cm)")

## OR 
all_dat_wcube <- mutate(all_data, cubeweight = Weight..g.^(1/3))
plot(all_dat_wcube$Fork.length..cm., all_dat_wcube$cubeweight,
     pch = 16, frame = FALSE, col = "blue", cex=0.5,
     ylab="Cube root weight (g)", xlab = "Fork length (cm)")


```

<br>

This looks very linear now. Let's use an actual statistical test to see if there is a correlation:

```{r}
cor.test(all_data$Fork.length..cm., cube_weight)
```

We have a very high correlation coefficient and a very low p value, cool. Remember, however, that we cube root transformed the weight data, so the interpretation is **not** that there is a linear relationship between weight and length. Rather there is a cubic relationship.

<br>
<br>

Since we have a hypothesis of causation (being larger causes a fish to be heavier), a linear regression is probably more appropriate here than a correlation test. This also allows us to plot out the regression line on our scatterplot:

```{r}
reg <- lm(all_dat_wcube$cubeweight ~ all_dat_wcube$Fork.length..cm.)
plot(all_dat_wcube$Fork.length..cm., all_dat_wcube$cubeweight,
     pch = 16, frame = FALSE, col = "blue", cex=0.5,
     ylab="Cube root weight (g)", xlab = "Fork length (cm)")
abline(reg, col="black")
```


Note that here, the order of weight and length in the regression formula is important because we are saying that weight is a function of length (i.e., that length is the predictor/independent variable), not simply asking if there is a correlation.


<br>
<br>

### Differences among groups

Beyond correlations among continuous variables, in many cases we are interested in differences in measurements among groups. Here we have several different species, and we expect that our measurements will differ across these. We'll take the same general approach as above, starting with some simple visualization, then explicitly testing for differences among groups. 


We can start by plotting out a distribution for a single species by filtering our data to a single species data and making a histogram.

```{r}
coho_weight <- all_data[all_data$Species=="Coho", "Weight..g."]
hist(coho_weight, breaks = 30, xlab = "Coho weight", main = NULL)
```

We can also plot multipe histograms together in different colors to get a sense for how distributions do or do not overlap. 

```{r}
dolly_weight <- all_data[all_data$Species=="Dolly varden", "Weight..g."]
hist(coho_weight, breaks = 20, xlab = "weight", main = NULL, xlim = c(0,70),
     col="blue")
hist(dolly_weight, breaks = 60, add = TRUE, col = "red")

```


<br>

A better way to plot this would be to make the histograms partially transparent. We won't explore that here, but as for most things in R, there are plenty of resources on the internet: https://stackoverflow.com/questions/3541713/how-to-plot-two-histograms-together-in-r

Even with some transparency, if we plotted all seven of our species, this would get hard to interpret pretty quickly. One option for plotting multiple distributions is to use box plots. Personally, I prefer violin plots from ggplot, but we'll get to those later on.


```{r}
par(mar=c(10,4.1,4.1,2.1))
boxplot(Weight..g. ~ Species, data = all_data, main="Fish weights",
   xlab = NULL, ylab = "Weight (g)", las = 2)
```


This looks ok. There is a lot more customization we could do with this, but again, we won't get into that here. The `par()` function sets graphical parameters, and we used it to set the margins `mar()` so that the bottom margin is wider than the default to accommodate the vertical labels. You can find more info [here](https://www.r-bloggers.com/2010/06/setting-graph-margins-in-r-using-the-par-function-and-lots-of-cow-milk/).

<br>

Let's write this plot out to pdf. You *can* save plots directly from RStudio using some GUI options, but the quality is not as good as plotting to a pdf or other image format using `pdf()`, `png()`, etc. I personally prefer pdf format because it is vector-based and maintains resolution under infinite zoom. We use the function `pdf()` to open a pdf plotting device, then plot like normal, but now everything being plotted goes to the pdf file that is open for writing. When we're done, we use `dev.off()` to turn off and close the active plotting device, leaving us with our completed pdf file.

```{r, message = FALSE, results = FALSE}
pdf(file="boplot.pdf", width=6, height=5)
par(mar=c(10,4.1,4.1,2.1))
boxplot(Weight..g. ~ Species, data = all_data, main="Fish weights",
   xlab = NULL, ylab = "Weight (g)", las = 2)
dev.off()

```

<br>

We can see here that it looks like we have some major differences in body sizes across the different fish species. Let's test that out using ANOVA.

**There are various ways to run ANOVAs in R, one is using the `aov()` function. This function is structured similarly to the `lm()` and `boxplot()` functions. Try using `?aov()` to figure out how to run an ANOVA that will tell us if body weights differe among species.** You might need to search the internet for how to specify formulas in R.

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


```{r}
res.aov <- aov(Weight..g. ~ Species, data = all_data)
summary(res.aov)
```

<br>

Looks like we have some some highly significant differences among the species here. ANOVA itself won't tell us what is different from what, though, so let's run a quick Tukey post-hoc test.

```{r, results = FALSE}
TukeyHSD(res.aov)
```

<br>



Keep in mind that ANOVA carries assumptions like equal variance among groups and normality that may be violated in this data. When running any test with such assumptions, you should be eplicitly testing that your data conform to them. If your data do not meet the test's assumptions, your results may be biased, and so data transformation or the use of a non-parametric test that does not carry the same assumptions may be a better alternative. You can find more detail on testing ANOVA assumptions and ANOVA alternatives in R here: http://www.sthda.com/english/wiki/one-way-anova-test-in-r

All statistical tests make certain assumptions about the data, and tests vary in how robust they are to violations of those assumptions. In the end, you will need to know the specifics of both your dataset and the relevant statistical tests to know what methods will be applicable to your data. 


<br>
<br>

# ggplot

<br>

`ggplot` is an extremely popular R package that can make all sorts of very nice graphics. If you get familiar with the general style of `ggplot`, you'll pretty quickly start to notice that many figures in research papers are made with this package.

<br>


### ggplot syntax

`ggplot` makes some very nice figures, but it has a whole syntax to it that can take a little while to learn. We'll make a quick plot, then explain what's going on here:

```{r}
ggplot(data = all_data) + 
  geom_point(mapping = aes(x = Fork.length..cm., y = Weight..g.))
```

<br>

All calls to `ggplot()` are composed of at least two pieces. The first simply specifies the object that contains the data. All of the data for the plot should be in a single object, with different variables in different columns and each row specifying a single observation of a data (this is part of the general "Tidy" data philosophy).

The basic `ggplot()` call without adding in a `geom` function will just render a blank plot, since you haven't told it what kind of plot to make with the data - this is unlike the base R `plot()` function we used above, which will try to guess what type of plot you want based on the nature of the data.

```{r, fig.show = 'hide'}
ggplot(data = all_data) # this makes an empty plot
```

<br>

In the full call:

```{r, fig.show = 'hide'}
ggplot(data = all_data) + 
  geom_point(mapping = aes(x = Fork.length..cm., y = Weight..g.))
```

The `geom_point()` function tells `ggplot` to plot out the data as points. Within this function, the `mapping` argument specifies how the data are mapped to the visualization. The mapping is specified using the `aes()` (aesthetic) function. Here we specify only which variable is x and which is y, but there are other things we can specify as well.

* Multiple `geom` functions can be combined into a single plot, and the `mapping` argument can be specified independently in each, or can be specified globally within the `ggplot()` function call.


<br>

### Aesthetic mappings 

We've so far plotted out two variables, but we can add information about additional variables by passing additional arguments to `aes()`. For example, we can change the shape the points by species:

```{r}
ggplot(data = all_data) + 
  geom_point(mapping = aes(x = Fork.length..cm., y = Weight..g., shape = Species))
```

* Note the warning that we can only assign up to 6 shapes to variables, and see that three spine stickleback has been left out because of this. 

<br>

Instead we can change the color by species:

```{r}
ggplot(data = all_data) + 
  geom_point(mapping = aes(x = Fork.length..cm., y = Weight..g., color = Species))
```

<br>

We can also scale the size of the points by some variable using the `size` argument in `aes()`. Try modifying the above plot so that the points are sized by `del15N`.

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>


```{r}
ggplot(data = all_data) + 
  geom_point(mapping = aes(
    x = Fork.length..cm., 
    y = Weight..g., 
    color = Species,
    size = del15N))
```

This is a very busy plot at this point, and for me, all points are too large to be interpretable, so let's add a function that controls the range of point sizes:

```{r}
ggplot(data = all_data) + 
  geom_point(mapping = aes(
    x = Fork.length..cm., 
    y = Weight..g., 
    color = Species,
    size = del15N)) +
  scale_size(range = c(0.1, 2))
```

This is a little better, but still is clearly not the best way to display these data. Just because you *can* plot things in a certain way, doesn't mean you *should* plot them that way.


<br>

If we want to change the color (or size, shape, etc.) of all points, rather than according to a variable, we can do this by pulling that aesthetic outside of the `aes()` function and setting it manually:

```{r}
ggplot(data = all_data) + 
  geom_point(mapping = aes(x = Fork.length..cm., y = Weight..g.), color = "blue")
```




<br>
<br>

[Home](https://wyoibc.github.io/r4grads/)

<br>
<br>


